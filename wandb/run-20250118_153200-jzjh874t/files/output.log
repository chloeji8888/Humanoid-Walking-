Actor MLP: Sequential(
  (0): Linear(in_features=39, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=10, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=39, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
################################################################################
                      [1m Learning iteration 0/3000 [0m

                       Computation: 32067 steps/s (collection: 4.703s, learning 1.428s)
               Value function loss: 0.0067
                    Surrogate loss: 0.0000
             Mean action noise std: 1.00
                       Mean reward: -0.03
               Mean episode length: 24.04
 Mean episode rew_tracking_lin_vel: 0.0113
 Mean episode rew_tracking_ang_vel: 0.0012
        Mean episode rew_lin_vel_z: -0.0001
      Mean episode rew_base_height: -0.0109
      Mean episode rew_action_rate: -0.0018
Mean episode rew_similar_to_default: -0.0009
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.13s
                        Total time: 6.13s
                               ETA: 18393.3s

################################################################################
                      [1m Learning iteration 1/3000 [0m

                       Computation: 42009 steps/s (collection: 3.725s, learning 0.955s)
               Value function loss: 0.0013
                    Surrogate loss: -0.0062
             Mean action noise std: 1.00
                       Mean reward: -0.01
               Mean episode length: 26.23
 Mean episode rew_tracking_lin_vel: 0.0170
 Mean episode rew_tracking_ang_vel: 0.0017
        Mean episode rew_lin_vel_z: -0.0001
      Mean episode rew_base_height: -0.0157
      Mean episode rew_action_rate: -0.0026
Mean episode rew_similar_to_default: -0.0013
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 4.68s
                        Total time: 10.81s
                               ETA: 16211.4s

################################################################################
                      [1m Learning iteration 2/3000 [0m

                       Computation: 41725 steps/s (collection: 3.758s, learning 0.954s)
               Value function loss: 0.0010
                    Surrogate loss: -0.0098
             Mean action noise std: 0.99
                       Mean reward: 0.02
               Mean episode length: 25.69
 Mean episode rew_tracking_lin_vel: 0.0180
 Mean episode rew_tracking_ang_vel: 0.0017
        Mean episode rew_lin_vel_z: -0.0001
      Mean episode rew_base_height: -0.0157
      Mean episode rew_action_rate: -0.0026
Mean episode rew_similar_to_default: -0.0014
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 4.71s
                        Total time: 15.52s
                               ETA: 15512.8s

################################################################################
                      [1m Learning iteration 3/3000 [0m

                       Computation: 44518 steps/s (collection: 3.468s, learning 0.948s)
               Value function loss: 0.0017
                    Surrogate loss: -0.0102
             Mean action noise std: 0.98
                       Mean reward: 0.05
               Mean episode length: 23.81
 Mean episode rew_tracking_lin_vel: 0.0188
 Mean episode rew_tracking_ang_vel: 0.0017
        Mean episode rew_lin_vel_z: -0.0001
      Mean episode rew_base_height: -0.0154
      Mean episode rew_action_rate: -0.0025
Mean episode rew_similar_to_default: -0.0014
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 4.42s
                        Total time: 19.94s
                               ETA: 14939.6s
